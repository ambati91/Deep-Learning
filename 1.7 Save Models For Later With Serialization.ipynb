{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Given that deep learning models can take hours, days and even weeks to train, it is important to know how to save and load them from disk."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. HDF5 Format\n",
    "The Hierarchical Data Format or HDF5 for short is a flexible data storage format and is\n",
    "convenient for storing large arrays of real values, as we have in the weights of neural networks.\n",
    "You may need to install Python support for the HDF5 file format. You can do this using your\n",
    "preferred Python package management system such as Pip: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: h5py in c:\\users\\alekh\\appdata\\local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages (2.9.0)\n",
      "Requirement already satisfied: six in c:\\users\\alekh\\appdata\\local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages (from h5py) (1.12.0)\n",
      "Requirement already satisfied: numpy>=1.7 in c:\\users\\alekh\\appdata\\local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages (from h5py) (1.16.5)\n"
     ]
    }
   ],
   "source": [
    "! pip install h5py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Save Your Neural Network Model to JSON\n",
    "- JSON is a simple file format for describing data hierarchically. Keras provides the ability to describe any model using JSON format with a to_json() function. This can be saved to file and later loaded via the model_from_json() function that will create a new model from the JSON specification.\n",
    "- The weights are saved directly from the model using the save_weights() function and later loaded using the symmetrical load_weights() function. The example below trains and evaluates a simple model on the Pima Indians dataset. The model structure is then converted to JSON format and written to model.json in the local directory. The network weights are written to model.h5 in the local directory.\n",
    "- The model and weight data is loaded from the saved files and a new model is created. It is important to compile the loaded model before it is used. This is so that predictions made using the model can use the appropriate efficient computation from the Keras backend. The model is evaluated in the same way printing the same evaluation score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 77.97%\n",
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# MLP fro Pima Indian Dataset Serialization to JSON and HDF5\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.models import model_from_json\n",
    "import numpy\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "# load pima indians dataset.\n",
    "dataframe = pd.read_csv('pima-indians-diabetes.csv')\n",
    "dataset = dataframe.values\n",
    "\n",
    "# split into input(X) and outut(Y) variable\n",
    "X = dataset[:,:8]\n",
    "Y = dataset[:,8]\n",
    "\n",
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim = 8, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "model.add(Dense(8, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "model.add(Dense(1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "\n",
    "# compile model\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "\n",
    "# fit the model\n",
    "model.fit(X,Y, nb_epoch = 150, batch_size = 10, verbose = 0)\n",
    "\n",
    "# eavaluate model\n",
    "scores = model.evaluate(X,Y, verbose = 0)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "\n",
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\",\"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "# serialize weitghts to HDF5\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load json and create model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n",
      "accuracy: 77.97%\n"
     ]
    }
   ],
   "source": [
    "json_file = open('model.json','r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    "\n",
    "# evaluate loaded model on test data\n",
    "loaded_model.compile(loss = 'binary_crossentropy', optimizer = 'rmsprop', metrics = ['accuracy'])\n",
    "score = loaded_model.evaluate(X,Y, verbose = 0)\n",
    "print (\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Save Your Neural Network Model to YAML\n",
    "This example is much the same as the above JSON example, except the YAML format is used\n",
    "for the model specification. The model is described using YAML, saved to file model.yaml and\n",
    "later loaded into a new model via the model_from_yaml() function. Weights are handled in the\n",
    "same way as above in HDF5 format as model.h5. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 77.05%\n",
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# MLP for Pima Indians Dataset serialize to YAML and HDF5\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.models import model_from_yaml\n",
    "import numpy\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "# load pima indians dataset.\n",
    "dataframe = pd.read_csv('pima-indians-diabetes.csv')\n",
    "dataset = dataframe.values\n",
    "\n",
    "# split into input(X) and outut(Y) variable\n",
    "X = dataset[:,:8]\n",
    "Y = dataset[:,8]\n",
    "\n",
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim = 8, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "model.add(Dense(8, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "model.add(Dense(1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "\n",
    "# compile model\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "\n",
    "# fit the model\n",
    "model.fit(X,Y, nb_epoch = 150, batch_size = 10, verbose = 0)\n",
    "\n",
    "# eavaluate model\n",
    "scores = model.evaluate(X,Y, verbose = 0)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "\n",
    "# serialize model to YAML\n",
    "model_yaml = model.to_yaml()\n",
    "with open(\"model.yaml\",\"w\") as yaml_file:\n",
    "    yaml_file.write(model_yaml)\n",
    "\n",
    "# serialize weitghts to HDF5\n",
    "model.save_weights(\"model_yaml.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load YAML and create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n",
      "accuracy: 77.05%\n"
     ]
    }
   ],
   "source": [
    "# load YAML and create model\n",
    "yaml_file = open( 'model.yaml' , 'r' )\n",
    "loaded_model_yaml = yaml_file.read()\n",
    "yaml_file.close()\n",
    "loaded_model = model_from_yaml(loaded_model_yaml)\n",
    "\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model_yaml.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    "\n",
    "# evaluate loaded model on test data\n",
    "loaded_model.compile(loss= 'binary_crossentropy' , optimizer= 'rmsprop' , metrics=[ 'accuracy' ])\n",
    "score = loaded_model.evaluate(X, Y, verbose=0)\n",
    "print (\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
